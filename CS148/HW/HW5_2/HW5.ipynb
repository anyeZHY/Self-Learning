{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74ed07c0",
   "metadata": {},
   "source": [
    "# HW5 Technical: Blender Scripting\n",
    "\n",
    "For this assignment, you'll be trying out the scripting options in blender, and creating a function that can predict the bunny and light's coordinate frames from an image:\n",
    "* TODO1 [Blender]: use the Blender scripting tool to rotate the bunny and light and render an image.\n",
    "* TODO2 [Blender]: use the Blender scripting tool to render a batch of images.\n",
    "* TODO3 [Blender]: for each image in the batch, record the corresponding orientation (pose) of the light and bunny in a json file.\n",
    "* TODO4 [notebook]: run the optimizer given, and generate a prediction.\n",
    "* TODO5 [Blender]: take the prediction, and use the Blender script to generate a render corresponding to that prediction.\n",
    "\n",
    "\n",
    "Before running this notebook , make sure you've run \n",
    "\n",
    "```conda install pytorch==1.10.1 torchvision==0.11.2 torchaudio==0.10.1 cpuonly -c pytorch```\n",
    "\n",
    "in your anaconda environment. If you forgot to do this, close jupyter notebook and run the installation command first.\n",
    "\n",
    "Also note again that you will not need to do any coding in the notebook for this assignment. Run the cells and verify that the output is correct, and respond to the short response questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d583457",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DO NOT EDIT\n",
    "import os, sys, glob, json\n",
    "from typing import Any, Dict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def show_image(filename:str, height:float=4, width:float=4,label:str=None):\n",
    "    img=cv2.imread(filename)\n",
    "    img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)        \n",
    "    plt.gca().grid(None)\n",
    "    plt.gca().axis(\"off\")\n",
    "    plt.imshow(img)\n",
    "    if label is not None:\n",
    "        plt.gca().set_title(label)\n",
    "    plt.gcf().set_size_inches((width,height))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4586a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running this cell, finish the TODO1 sections in the Blender file.\n",
    "show_image(\"images/todo1.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4defa96",
   "metadata": {},
   "source": [
    "# Short Response\n",
    "* What are the rotation angles z_bunny and z_light for `todo1.png`? (Check the code in the Blender file that resulted in this output.)\n",
    "\n",
    "```Your answer here```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70f958f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running this cell, finish the TODO2 and TODO3 sections in the Blender file.\n",
    "def show_images(parameter_dict:Dict[str,Any], scale:float=1):\n",
    "    num_images=len(parameter_dict)\n",
    "    num_columns=int(np.ceil(num_images**0.5))\n",
    "    num_rows=(num_images+num_columns-1)//num_columns\n",
    "    \n",
    "    fig,axes=plt.subplots(num_rows,num_columns,gridspec_kw={'wspace':0, 'hspace':0.2})\n",
    "    filenames=sorted(parameter_dict.keys())\n",
    "    for i,filename in enumerate(filenames):\n",
    "        parameters=parameter_dict[filename]\n",
    "        img=cv2.imread(f\"images/{filename}\")\n",
    "        img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)        \n",
    "        y,x=divmod(i,num_columns)\n",
    "        ax=axes[y][x]\n",
    "        ax.grid(None)\n",
    "        ax.axis(\"off\")\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f\"light:{int(parameters['z_light']):<4} bunny:{int(parameters['z_bunny']):<4}\")\n",
    "    fig.set_size_inches((scale*num_rows,scale*num_columns))\n",
    "    plt.show()\n",
    "    \n",
    "with open(\"todo2.json\",\"r\") as fp:\n",
    "    parameter_dict=json.load(fp)\n",
    "show_images(parameter_dict,scale=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24c0237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After verifying that the images above have the correct labels as printed in the grid\n",
    "# run this cell\n",
    "torch.manual_seed(148)\n",
    "rng = np.random.default_rng(148)\n",
    "\n",
    "#load images in a way our optimization framework can read\n",
    "def load_single_image(filename):\n",
    "    image=cv2.imread(f\"images/{filename}\")\n",
    "    image=torch.from_numpy(np.stack([image],axis=0).transpose(0,3,1,2)).float()/255.0 -0.5\n",
    "    return image\n",
    "def load_images_and_z_angles(filenames:str, param_dict):\n",
    "    images=[cv2.imread(f\"images/{filename}\") for filename in filenames]\n",
    "    z_angles=[[param_dict[f][\"z_light\"],param_dict[f][\"z_bunny\"]] for f in filenames]\n",
    "    images=torch.from_numpy(np.stack(images,axis=0).transpose(0,3,1,2)).float()/255.0 -0.5\n",
    "    z_angles=torch.Tensor(z_angles)/180.\n",
    "    return images, z_angles\n",
    "\n",
    "# define the problem: find G that minimizes ||G(yi)-xi||, \n",
    "# where yi is our observed images, and xi is our observed (z_light, z_bunny).\n",
    "# once we find a G that can predict xi from yi, \n",
    "# we can try predicting additional images that weren't previously observed!\n",
    "\n",
    "#setup a parametrization for G\n",
    "G = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 4, 3, padding=1, stride=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(4, 4, 3, padding=1, stride=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(4, 8, 3, padding=1, stride=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(8, 8, 3, padding=1, stride=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(512, 8),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(8, 2),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "\n",
    "distance_fn = torch.nn.MSELoss(reduction='sum')\n",
    "solver = torch.optim.RMSprop(G.parameters(), lr=10**(-3))\n",
    "\n",
    "num_images = len(parameter_dict)\n",
    "filenames=list(parameter_dict.keys())\n",
    "\n",
    "average_dists=[]\n",
    "for t in tqdm.notebook.tqdm(range(100)):\n",
    "    random_order=np.arange(num_images)\n",
    "    rng.shuffle(random_order)\n",
    "    random_order=np.array_split(random_order,1)\n",
    "    dists=[]\n",
    "    for batch in random_order:\n",
    "        #load in some xi, yi\n",
    "        batch_filenames=[filenames[i] for i in batch]\n",
    "        images, poses=load_images_and_z_angles(batch_filenames, parameter_dict)\n",
    "        # Compute G(yi)\n",
    "        pose_pred = G(images)\n",
    "        # Compute ||G(yi)-xi||\n",
    "        dist = distance_fn(pose_pred, poses)\n",
    "        # Minimize ||G(yi)-xi|| using optimization techniques to walk down the hill (gradient descent)\n",
    "        # Set initial downhill direction to zero\n",
    "        solver.zero_grad()\n",
    "        # Find downhill direction: compute gradient of the distance with respect to parameters of G\n",
    "        dist.backward()\n",
    "        # Step in some direction that we think takes us downhill\n",
    "        solver.step()\n",
    "        dists.append(dist.item())\n",
    "    average_dists.append(np.mean(dists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb0818b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    unseen_image=load_single_image(\"todo1.png\")\n",
    "    unseen_pose=G(unseen_image)[0].numpy()*180\n",
    "    prediction={\"predicted_z_light\":unseen_pose[0], \"predicted_z_bunny\":unseen_pose[1]}\n",
    "    print(prediction)\n",
    "    print(\"load this prediction into Blender's TODO5!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7e0f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell after doing TODO5 in Blender\n",
    "show_image(\"images/todo1.png\",label=\"original image y\")\n",
    "show_image(\"images/todo5.png\",label=\"render corresponding to pose from G(y)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99ff16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE THE SCRIPT IN BLENDER (Text -> Save or Alt/Option+S), \n",
    "# THEN RUN THIS CELL BEFORE SUBMITTING.\n",
    "# READ THE LOADED CODE AND MAKE SURE ALL YOUR TODOs HAVE BEEN UPDATED !!\n",
    "%load hw5_blender.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
